---
title: '**Heart Failure Prediction**'
subtitle: HarvardX Data Science Professional Certificate
author: "Narendra Kumar Jangid"
date: "2022-09-26"
output:
  pdf_document:
    number_sections: yes
    toc: yes
    toc_depth: 3
    fig_caption: yes
include-before: '`\newpage{}`{=latex}'
fontsize: 11pt
urlcolor: blue
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE, fig.align="center", out.width="65%")
```
\floatplacement{figure}{H}
\newpage


# **Introduction**   

Cardiovascular diseases (CVDs) are the leading cause of death worldwide. As per [World Health Organisation (WHO)](https://www.who.int), 17.9 Million people died in the year 2019 from CVDs, an estimated 32% of all deaths worldwide[1]. 

Heart Failure is an event caused by CVDs where the heart is not able to pump enough blood to meet the bodyâ€™s needs for blood and oxygen. The most common risk factors include High Blood Pressure, Obesity, Age and Genetics.

This project is a requirement for the HarvardX Data Science Professional Certificate Program which aims to develop the Heart Failure Prediction Model using the Heart Failure Clinical Records Data Set.

The report is created using R Markdown in [RStudio](https://www.rstudio.com/products/rstudio) that covers Data Preparation for Model Building, Data Exploration with common visualization techniques, Model Development using train and test sets, Model Evaluation and Results using validation set and Concluding Remarks.

## Objective

The objective of this project is to develop the Heart Failure Prediction Model using machine learning techniques to assess the likelihood of death by a heart failure event. The model can help identify the at-risk individuals and prevent fatal outcomes with appropriate treatment at an early stage.

The data is split into training, testing and validation sets to develop and validate the model. Models are evaluated using Model Performance metrics.

## Heart Failure Clinical Records Data Set

[Heart Failure Clinical Records Data Set](https://archive.ics.uci.edu/ml/datasets/Heart+failure+clinical+records) is taken from [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/index.php). The data set contains the medical records of 299 patients who have had heart failure, collected during their follow-up period where each patient profile has 13 clinical features[2].


# **Data Preparation**  

In the data preparation step, Heart Failure Clinical Records Data Set is prepared for exploration, modeling and model evaluation using required packages and libraries.

## Install Required Packages

To prepare and transform the data, required packages are installed and necessary libraries are loaded.

```{r}
# Install packages
if(!require(tidyverse)) install.packages("tidyverse", repos = "http://cran.us.r-project.org")
if(!require(caret)) install.packages("caret", repos = "http://cran.us.r-project.org")
if(!require(data.table)) install.packages("data.table", repos = "http://cran.us.r-project.org")
if(!require(ggplot2)) install.packages("ggplot2", repos = "http://cran.us.r-project.org")
if(!require(dplyr)) install.packages("dplyr", repos = "http://cran.us.r-project.org")
if(!require(lubridate)) install.packages("lubridate", repos = "http://cran.us.r-project.org")
if(!require(knitr)) install.packages("knitr", repos = "http://cran.us.r-project.org")
if(!require(kableExtra)) install.packages("kableExtra", repos = "http://cran.us.r-project.org")
if(!require(scales)) install.packages("scales", repos = "http://cran.us.r-project.org")
if(!require(stringr)) install.packages("stringr", repos = "http://cran.us.r-project.org")
if(!require(ggpubr)) install.packages("ggpubr", repos = "http://cran.us.r-project.org")
if(!require(naivebayes)) install.packages("naivebayes", repos = "http://cran.us.r-project.org")
if(!require(funModeling)) install.packages("funModeling", repos = "http://cran.us.r-project.org")
if(!require(ggcorrplot)) install.packages("ggcorrplot", repos = "http://cran.us.r-project.org")
if(!require(randomForest)) install.packages("randomForest", repos = "http://cran.us.r-project.org")
# Load required libraries
library(tidyverse)
library(caret)
library(data.table)
library(ggplot2)
library(dplyr)
library(lubridate)
library(knitr)
library(kableExtra)
library(scales)
library(stringr)
library(ggpubr)
library(naivebayes)
library(funModeling)
library(ggcorrplot)
library(randomForest)
```


## Create Heart Failure Data Set

The Heart Failure Clinical Records Data Set is read from the source and processed further to create Heart Failure data in the required format. Further processing of data includes having more descriptive data set values and converting required data set fields to factors and integers.

```{r}
# Read the Heart Failure Data set
heart_failure_data <- read.csv("https://archive.ics.uci.edu/ml/machine-learning-databases/00519/heart_failure_clinical_records_dataset.csv")
# Modify data set into having more descriptive values
heart_failure_data <- heart_failure_data %>% mutate(anaemia = ifelse(anaemia == 0,"No","Yes"), 
                                                    diabetes = ifelse(diabetes == 0,"No","Yes"),
                                                    high_blood_pressure = ifelse(high_blood_pressure == 0,"No","Yes"),
                                                    sex = ifelse(sex == 0, "Female", "Male"),
                                                    smoking = ifelse(smoking == 0, "No","Yes"),
                                                    DEATH_EVENT = ifelse(DEATH_EVENT == 0, "No","Yes"))
# Convert required data set fields to factor and integer
column_factor <- c("anaemia", "diabetes", "high_blood_pressure", "sex", "smoking", "DEATH_EVENT")
heart_failure_data[column_factor] <- lapply(heart_failure_data[column_factor], as.factor)
column_int <- c("age", "creatinine_phosphokinase", "ejection_fraction", "platelets", "serum_sodium", "time")
heart_failure_data[column_int] <- lapply(heart_failure_data[column_int], as.integer)
```

## Create Train and Validation Sets

The Heart Failure data is split into two parts, training set and testing set with 90% and 10% of the original data set respectively. The training set is called edx and the testing set is called the validation set. 

The model development is done using the edx set with further split into train and test data sets whereas the validation set is the final test set that is used at the end to check the model performance.

The 90:10 split is taken to have a reasonable number of instances in train, test and validation sets along with the best possible model performance for both test and validation sets.

```{r}
# Splitting the data into Train and Validation Set
set.seed(1, sample.kind="Rounding") 
test_index <- createDataPartition(y = heart_failure_data$DEATH_EVENT, times = 1, p = 0.1, list = FALSE)
edx <- heart_failure_data[-test_index,]
validation <- heart_failure_data[test_index,]
```

```{r}
# Drop unnecessary variables and data set
rm(test_index, column_factor, column_int)
```


# **Data Exploration and Analysis**  

Data exploration and analysis with different visualization techniques help us understand the data and its distribution resulting in a better model building. Density plots and Bar plots are majorly used visuals for Continuous and Categorical variables respectively.

Also, the analysis helps identify the Variable Importance and Correlation that can be taken into account while model building.

## Data Overview

The edx data set is a `r class(edx)` comprised of `r nrow(edx)` rows and `r ncol(edx)` columns. A record represents whether a heart failure patient having certain Gender, Sex and other Clinical Features has survived or not. 

An overview of the edx data is tabulated in Table 1.

```{r}
# Data Overview
head(edx,5) %>% knitr::kable(row.names=FALSE, caption = "edx Data Overview", booktabs = T, linesep = "", align="c") %>% kable_styling(full_width = FALSE, position = "center", row_label_position = "c", latex_options = c("hold_position", "scale_down"))
```

Below is the detailed definition of each of the 13 clinical features[2]: 

#.	Age: Age of the patient (Years)
#.	Anaemia: Decrease of red blood cells or hemoglobin (Yes/No)
#.	Creatinine Phosphokinase (CPK): Level of the CPK enzyme in the blood (mcg/L)
#.	Diabetes: If the patient has diabetes (Yes/No)
#.	Ejection Fraction: Percentage of blood leaving the heart at each contraction (Percentage)
#.	High Blood Pressure: If the patient has hypertension  (Yes/No)
#.	Platelets: Platelets in the blood (kiloplatelets/mL)
#.	Serum Creatinine: Level of serum creatinine in the blood (mg/dL)
#.	Serum Sodium: Level of serum sodium in the blood (mEq/L)
#.	Sex: Male or Female
#.	Smoking: If the patient smokes or not (Yes/No)
#.	Time: Follow-up period (Days)
#.	Death Event: If the patient deceased during the follow-up period (Yes/No)


## Death Event

```{r fig.cap="Death Event Distribution"}
# Plotting Death Event Distribution
ggarrange(edx %>% group_by(DEATH_EVENT) %>% summarise(count = n()) %>% ggplot(aes(x = DEATH_EVENT, y = count, fill= DEATH_EVENT)) + geom_bar(stat = "identity") + labs(x = "Death Event",y = "Count") + geom_text(aes(label = count), nudge_y = 5) + theme(legend.position="bottom") +  scale_fill_discrete(name='Death Event'),
          edx %>% group_by(DEATH_EVENT) %>% summarise(count = n()) %>% mutate(percentage_death_event = round(100*count/sum(count),1)) %>% ggplot(aes(x = DEATH_EVENT, y = percentage_death_event, fill= DEATH_EVENT)) + geom_bar(stat = "identity") + labs(x = "Death Event",y = "% Death Event") + geom_text(aes(label = round((percentage_death_event),0)), nudge_y = 2) + theme(legend.position="bottom") +  scale_fill_discrete(name='Death Event'),
          common.legend = TRUE, align = "h", legend = "bottom")
```

Figure 1 shows that 68% of patients have survived and 32% have died from a clinical record of 268 patients having Heart Failure.

## Age

```{r fig.cap="Age Distribution"}
# Plotting Age Distribution
ggarrange(edx %>% ggplot(aes(x=age, fill=DEATH_EVENT)) + geom_density(alpha=0.2)+ labs(x = "Age",y = "Density") + theme(legend.position="bottom") + scale_fill_discrete(name='Death Event'),
          edx %>% ggplot(aes(age, color = DEATH_EVENT)) + stat_ecdf(geom = "step") + labs(x = "Age",y = "Cumulative Density")+ theme(legend.position="bottom"),
          common.legend = TRUE, align = "h", legend = "bottom")
```

There is a higher likelihood of Death for patients having an age of 70 Years and above. Cumulative Death likelihood is lower than Survival with bigger differences at the age of 55, 65 and 70. Therefore, the death risk for a patient increases more rapidly as the patient reaches the age range of 50-80 Years.

## Anaemia

```{r fig.cap="Anaemia Distribution"}
# Plotting Anaemia Distribution
ggarrange(edx %>% group_by(anaemia, DEATH_EVENT) %>% summarise(count = n()) %>% ggplot(aes(x= anaemia, y=count, fill=DEATH_EVENT))+ geom_bar(stat="identity") + labs(x = "Anaemia",y = "Count") + geom_text(aes(label = count), nudge_y = -10) + theme(legend.position="bottom") + scale_fill_discrete(name='Death Event'),
          edx %>% group_by(anaemia, DEATH_EVENT) %>% summarise(count = n()) %>% mutate(percent_death_event = round(100*count/sum(count),1)) %>% ggplot(aes(x= anaemia, y= percent_death_event, fill=DEATH_EVENT))+ geom_bar( stat="identity") + labs(x = "Anaemia",y = "Death Event %") + geom_text(aes(label = round(percent_death_event,0)), nudge_y = -10) + theme(legend.position="bottom") + scale_fill_discrete(name='Death Event'),
          common.legend = TRUE, align = "h", legend = "bottom")
```

A Patient having Anaemia has a 37% likelihood of Death, 9% higher than a patient having no Anaemia.  

## Creatinine Phosphokinase

```{r fig.cap="Creatinine Phosphokinase Distribution"}
# Plotting Creatinine Phosphokinase Distribution
ggarrange(edx %>% ggplot(aes(x=creatinine_phosphokinase, fill=DEATH_EVENT)) + geom_density(alpha=0.2)+ labs(x = "Creatinine Phosphokinase",y = "Density") + theme(legend.position="bottom") + scale_fill_discrete(name='Death Event'),
          edx %>% ggplot(aes(creatinine_phosphokinase, color = DEATH_EVENT)) + stat_ecdf(geom = "step") + labs(x = "Creatinine Phosphokinase",y = "Cumulative Density")+ theme(legend.position="bottom"),
          common.legend = TRUE, align = "h", legend = "bottom")
```

No significant difference is observed between Death and Survival likelihood for different Creatinine Phosphokinase levels.

## Diabetes

```{r fig.cap="Diabetes Distribution"}
# Plotting Diabetes Distribution
ggarrange(edx %>% group_by(diabetes, DEATH_EVENT) %>% summarise(count = n()) %>% ggplot(aes(x= diabetes, y=count, fill=DEATH_EVENT))+ geom_bar(stat="identity") + labs(x = "Diabetes",y = "Count") + geom_text(aes(label = count), nudge_y = -10) + theme(legend.position="bottom") + scale_fill_discrete(name='Death Event'),
          edx %>% group_by(diabetes, DEATH_EVENT) %>% summarise(count = n()) %>% mutate(percent_death_event = round(100*count/sum(count),1)) %>% ggplot(aes(x= diabetes, y= percent_death_event, fill=DEATH_EVENT))+ geom_bar( stat="identity") + labs(x = "Diabetes",y = "Death Event %") + geom_text(aes(label = round(percent_death_event,0)), nudge_y = -10) + theme(legend.position="bottom") + scale_fill_discrete(name='Death Event'),
          common.legend = TRUE, align = "h", legend = "bottom")
```

Diabetes does not make a significant difference in the Survival and Death likelihood of a patient having heart failure.

## Ejection Fraction

```{r fig.cap="Ejection Fraction Distribution"}
# Plotting Ejection Fraction Distribution
ggarrange(edx %>% ggplot(aes(x=ejection_fraction, fill=DEATH_EVENT)) + geom_density(alpha=0.2)+ labs(x = "Ejection Fraction",y = "Density") + theme(legend.position="bottom") + scale_fill_discrete(name='Death Event'),
          edx %>% ggplot(aes(ejection_fraction, color = DEATH_EVENT)) + stat_ecdf(geom = "step") + labs(x = "Ejection Fraction",y = "Cumulative Density")+ theme(legend.position="bottom"),
          common.legend = TRUE, align = "h", legend = "bottom")
```

There is a higher likelihood of a patient`s Survival for an Ejection Fraction value of 30 and above. Also, the Survival likelihood peaks between the range of 35-40 and at 60 percent. Cumulative Death likelihood is higher than Survival being around three times higher between the Ejection Fraction range 25-30% and 30%-35%, upper and lower values excluded.  

## High Blood Pressure

```{r fig.cap="High Blood Pressure Distribution"}
# Plotting High Blood Pressure Distribution
ggarrange(edx %>% group_by(high_blood_pressure, DEATH_EVENT) %>% summarise(count = n()) %>% ggplot(aes(x= high_blood_pressure, y=count, fill=DEATH_EVENT))+ geom_bar(stat="identity") + labs(x = "High Blood Pressure",y = "Count") + geom_text(aes(label = count), nudge_y = -10) + theme(legend.position="bottom") + scale_fill_discrete(name='Death Event'),
          edx %>% group_by(high_blood_pressure, DEATH_EVENT) %>% summarise(count = n()) %>% mutate(percent_death_event = round(100*count/sum(count),1)) %>% ggplot(aes(x= high_blood_pressure, y= percent_death_event, fill=DEATH_EVENT))+ geom_bar( stat="identity") + labs(x = "High Blood Pressure",y = "Death Event %") + geom_text(aes(label = round(percent_death_event,0)), nudge_y = -10) + theme(legend.position="bottom") + scale_fill_discrete(name='Death Event'),
          common.legend = TRUE, align = "h", legend = "bottom")
```

A Patient having High Blood Pressure has a 35% likelihood of Death, 5% higher than a patient having no High Blood Pressure.   

## Platelets

```{r fig.cap="Platelets Distribution"}
# Plotting Platelets Distribution
ggarrange(edx %>% ggplot(aes(x=platelets, fill=DEATH_EVENT)) + geom_density(alpha=0.2)+ scale_x_log10() + labs(x = "Platelets (log10)",y = "Density") + theme(legend.position="bottom") + scale_fill_discrete(name='Death Event'),
          edx %>% ggplot(aes(platelets, color = DEATH_EVENT)) + stat_ecdf(geom = "step") + scale_x_log10() + labs(x = "Platelets (log10)",y = "Cumulative Density")+ theme(legend.position="bottom"),
          common.legend = TRUE, align = "h", legend = "bottom")
```

There is a higher likelihood of Death for lower values of platelets whereas no difference is observed for higher values. Also, a higher likelihood of Survival is observed at the peak. Cumulative Death likelihood is higher than Survival for lower values of platelets whereas no significant difference is observed in Cumulative Death and Survival likelihood for higher values of blood platelets. 

## Serum Creatinine

```{r fig.cap="Serum Creatinine Distribution"}
# Plotting Serum Creatinine Distribution
ggarrange(edx %>% ggplot(aes(x=serum_creatinine, fill=DEATH_EVENT)) + geom_density(alpha=0.2)+ labs(x = "Serum Creatinine",y = "Density") + theme(legend.position="bottom") + scale_fill_discrete(name='Death Event'),
          edx %>% ggplot(aes(serum_creatinine, color = DEATH_EVENT)) + stat_ecdf(geom = "step") + labs(x = "Serum Creatinine",y = "Cumulative Density")+ theme(legend.position="bottom"),
          common.legend = TRUE, align = "h", legend = "bottom")
```

There is a higher likelihood of Survival for Serum Creatinine levels of 1.25 mg/dL or below. Cumulative Survival likelihood is higher than Death which improves significantly between Serum Creatinine value 1.25 -2.5 mg/dL.

## Serum Sodium

```{r fig.cap="Serum Sodium Distribution"}
# Plotting Serum Sodium Distribution
ggarrange(edx %>% ggplot(aes(x=serum_sodium, fill=DEATH_EVENT)) + geom_density(alpha=0.2)+ labs(x = "Serum Sodium",y = "Density") + theme(legend.position="bottom") + scale_fill_discrete(name='Death Event'),
          edx %>% ggplot(aes(serum_sodium, color = DEATH_EVENT)) + stat_ecdf(geom = "step") + labs(x = "Serum Sodium",y = "Cumulative Density")+ theme(legend.position="bottom"),
          common.legend = TRUE, align = "h", legend = "bottom")
```

Serum Sodium level of 135 mEq/L or above results in a higher likelihood of Survival. Cumulative Death likelihood is higher than Survival for Serum Sodium levels below 140 mEq/L. Also, the Cumulative Death likelihood almost becomes double the Survival at Serum Sodium level of 135 mEq/L.

## Sex

```{r fig.cap="Sex Distribution"}
# Plotting Sex Distribution
ggarrange(edx %>% group_by(sex, DEATH_EVENT) %>% summarise(count = n()) %>% ggplot(aes(x= sex, y=count, fill=DEATH_EVENT))+ geom_bar(stat="identity") + labs(x = "Sex",y = "Count") + geom_text(aes(label = round(count,0)), nudge_y = -10) + theme(legend.position="bottom") + scale_fill_discrete(name='Death Event'),
          edx %>% group_by(sex, DEATH_EVENT) %>% summarise(count = n()) %>% mutate(percent_death_event = round(100*count/sum(count),1)) %>% ggplot(aes(x= sex, y= percent_death_event, fill=DEATH_EVENT))+ geom_bar( stat="identity") + labs(x = "Sex",y = "Death Event %") + geom_text(aes(label = round(percent_death_event,0)), nudge_y = -10)  + theme(legend.position="bottom") + scale_fill_discrete(name='Death Event'),
          common.legend = TRUE, align = "h", legend = "bottom")
```

The sex of a patient has no significant impact on Survival and Death likelihood.

## Smoking

```{r fig.cap="Smoking Distribution"}
# Plotting Smoking Distribution
ggarrange(edx %>% group_by(smoking, DEATH_EVENT) %>% summarise(count = n()) %>% ggplot(aes(x= smoking, y=count, fill=DEATH_EVENT))+ geom_bar(stat="identity") + labs(x = "Smoking",y = "Count") + geom_text(aes(label = round(count,0)), nudge_y = -10) + theme(legend.position="bottom") + scale_fill_discrete(name='Death Event'),
          edx %>% group_by(smoking, DEATH_EVENT) %>% summarise(count = n()) %>% mutate(percent_death_event = round(100*count/sum(count),1)) %>% ggplot(aes(x= smoking, y= percent_death_event, fill=DEATH_EVENT))+ geom_bar( stat="identity") + labs(x = "Smoking",y = "Death Event %") + geom_text(aes(label = round(percent_death_event,0)), nudge_y = -10) + theme(legend.position="bottom") + scale_fill_discrete(name='Death Event'),
          common.legend = TRUE, align = "h", legend = "bottom")
```

A patient having a Smoking habit has a higher Survival likelihood compared to a non-smoker which is conflicting.

## Time

A follow-up period of around 80 days or above results in a higher likelihood of a patient`s Survival having Heart Failure.

```{r fig.cap="Time Distribution"}
# Plotting Time Distribution
ggarrange(edx %>% ggplot(aes(x=time, fill = DEATH_EVENT)) + geom_density(alpha=0.2)+ labs(x = "Time",y = "Density") + theme(legend.position="bottom") + scale_fill_discrete(name='Death Event'),
          edx %>% ggplot(aes(time, color = DEATH_EVENT)) + stat_ecdf(geom = "step") + labs(x = "Time",y = "Cumulative Density")+ theme(legend.position="bottom"),
          common.legend = TRUE, align = "h", legend = "bottom")
```

The Cumulative Death Rate is significantly higher than the Survival Rate being almost 2 times higher at the Time value of 78. Also, the Survival Rate improves over the follow-up period as delta reduces.

## Variable Importance and Correlation

**Variable Importance:**

Variable (Feature) Importance is estimated using information theory that ranks the best features basis several metrics between features and target variable[3].

Figure 14 shows that time is the most important feature followed by creatinine phosphokinase and platelets whereas sex, diabetes and smoking are the least important ones. The least important features must be excluded while developing the model to reduce complexity and improve accuracy.

**Variable Correlation:**

Variable correlation helps find variables that are related. Independent Variables or Predictor having strong correlation should be excluded from the model to reduce complexity as a correlated variable does not add any additional information to the model[4].

Figure 15 shows that there is moderate to weak correlation among features and feature exclusion is not required basis the Correlation insights.

```{r fig.cap="Variable Importance basis Information Gain"}
# Variable Importance basis Information Gain
ggplot(var_rank_info(edx, "DEATH_EVENT"), aes(x = reorder(var, gr), y = gr, fill = var)) + geom_bar(stat = "identity") + coord_flip() + theme_bw() + xlab("") + ylab("Variable Importance") + guides(fill = FALSE)
```

```{r fig.cap="Variable Correlation"}
# Variable Correlation
round(cor(edx[c(1,3,5,7,8,9,12)]),3) %>% ggcorrplot(hc.order = TRUE, outline.color = "white") + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
```


# **Model Development and Results** 

The Heart Failure Prediction Model is developed using the edx set and the final test is performed on the reserved validation set. Three features (sex, diabetes, smoking) are excluded from Model building and Validation to reduce complexity as no significant information is contributed by these features.

```{r}
# Exclude least important features from edx and validation set
edx <- edx %>% select(-sex, -diabetes, -smoking)
validation <- validation %>% select(-sex, -diabetes, -smoking)
```

## Splitting edx Data into Train and Test Sets

The edx data is split into the training set and testing set with 90% and 10% of the original edx set respectively. The training set is called edx_train_set and the testing set is called the edx_test_set. The model is developed using the edx_train_set and testing is performed on edx_test_set before the final test on the validation set.

```{r}
# Split edx data into test and train sets
set.seed(1, sample.kind = "Rounding")
test_index <- createDataPartition(y = edx$DEATH_EVENT, times = 1, p = 0.1, list = FALSE)
edx_train_set <- edx[-test_index,]
edx_test_set <- edx[test_index,]
```

```{r}
# Drop unnecessary variables and data set
rm(test_index)
```

## Model Performance Metrics

Confusion Matrix can help estimate the performance or accuracy of a Classification Model. Confusion Matrix tabulates the Actual and Model Predicted Outcomes as shown below.      

```{r}
matrix(c("True Positives (TP)", "False Positive (FP)", "False Negative (FN)", "True Negative (TN)"), nrow =2, ncol = 2,dimnames = list(c("Actual Positive", "Actual Negative"), c("Predicted Positive", "Predicted Negative"))) %>% knitr::kable(caption = "Confusion Matrix", booktabs = T, linesep = "", align="c") %>% kable_styling(full_width = FALSE, position = "center", row_label_position = "c", latex_options = c("hold_position"))
```

- True Positive: Actual = Positive, Predicted = Positive
- True Negative: Actual = Negative, Predicted = Negative
- False Positive: Actual = Negative, Predicted = Positive
- False Negative: Actual = Positive, Predicted = Negative 

Accuracy: Accuracy is defined as the percentage of correct predictions. It can be calculated by dividing the number of correct predictions by the number of total predictions[5].

$$Accuracy =\frac{TP+TN}{TP+FP+FN+TN}$$ 

Sensitivity: Sensitivity is defined as True Positive Rate. It can be calculated by dividing the number of True Positive predictions by total number of Positive predictions[5].

$$Sensitivity =\frac{TP}{TP+FP}$$ 

Specificity: Specificity is defined as True Negative Rate. It can be calculated by dividing the number of True Negative predictions by total number of Negative predictions[5].

$$Specificity =\frac{TN}{FN+TN}$$ 


## Model Development, Validation and Results 

Classification Models are explored for Model Development as the Heart Failure Data has categorical dependent attribute.


### Generalized Linear Model (glm)

Generalized Linear Model is an Umbrella term that consists of models like Linear Regression and Logistic Regression. Logistic regression is also called the logistic model or logit model. Logistic Regression analyzes the relationship between multiple independent variables and a categorical dependent variable. It estimates the probability of occurrence of an event by fitting data to a logistic curve[6].

```{r}
# Model Training and Testing
set.seed(1, sample.kind = "Rounding")
# Model Training
glm_train <- train(DEATH_EVENT~.,data = edx_train_set, method = "glm")
# Model Testing
glm_test <- predict(glm_train, edx_test_set)
# Model Accuracy On Test Set using Confusion Matrix
glm_test_cfm <- confusionMatrix(glm_test, edx_test_set$DEATH_EVENT, positive = "Yes")
glm_test_accuracy <- glm_test_cfm$overall["Accuracy"]
glm_test_sensitivity <- glm_test_cfm$byClass["Sensitivity"]
glm_test_specificity <- glm_test_cfm$byClass["Specificity"]
Model_test_Accuracy <- tibble(Model = "Generalized Linear Model (glm)", Accuracy = glm_test_accuracy, Sensitivity = glm_test_sensitivity, Specificity = glm_test_specificity)
```

```{r}
# Model Validation
glm_validation <- predict(glm_train, newdata = validation)
# Model Accuracy On Validation Set using Confusion Matrix
glm_validation_cfm <- confusionMatrix(glm_validation, validation$DEATH_EVENT, positive = "Yes")
glm_validation_accuracy <- glm_validation_cfm$overall["Accuracy"]
glm_validation_sensitivity <- glm_validation_cfm$byClass["Sensitivity"]
glm_validation_specificity <- glm_validation_cfm$byClass["Specificity"]
Model_validation_Accuracy <- tibble(Model = "Generalized Linear Model (glm)", Accuracy = glm_validation_accuracy, Sensitivity = glm_validation_sensitivity, Specificity = glm_validation_specificity)
# Remove redundant variables
rm(glm_train, glm_test,glm_test_cfm, glm_test_accuracy, glm_test_sensitivity, glm_test_specificity, glm_validation, glm_validation_cfm, glm_validation_accuracy, glm_validation_sensitivity, glm_validation_specificity)
```

The calculated model performance metrics on the edx test set are listed below in Table 3.

```{r}
# Model Accuracy on Test Set
Model_test_Accuracy %>% knitr::kable(row.names=FALSE, caption = "Model Accuracy on Test Set", booktabs = T, linesep = "", align = "lccc", digits=5) %>% kable_styling(full_width = FALSE, latex_options = c("hold_position"))
```

The calculated model performance metrics on the validation set are listed below in Table 4.

```{r}
# Model Accuracy on Validation Set
Model_validation_Accuracy %>% knitr::kable(row.names=FALSE, caption = "Model Accuracy on Validation Set", booktabs = T, linesep = "", align = "lccc", digits=5) %>% kable_styling(full_width = FALSE, position = "center", latex_options = c("hold_position"))
```


### Naive Bayes (naive_bayes)

The Naive Bayes algorithm, a probabilistic classifier is based on Bayes Theorem and used for solving high dimensional classification problems. It assumes features are independent of each other, such that each feature independently and equally contributes to the probability of a sample belonging to a specific class[7]. 

```{r}
# Model Training and Testing
set.seed(1, sample.kind = "Rounding")
# Model Training
naive_bayes_train <- train(DEATH_EVENT~.,data = edx_train_set, method = "naive_bayes")
# Model Testing
naive_bayes_test <- predict(naive_bayes_train, edx_test_set)
# Model Accuracy On Test Set using Confusion Matrix
naive_bayes_test_cfm <- confusionMatrix(naive_bayes_test, edx_test_set$DEATH_EVENT, positive = "Yes")
naive_bayes_test_accuracy <- naive_bayes_test_cfm$overall["Accuracy"]
naive_bayes_test_sensitivity <- naive_bayes_test_cfm$byClass["Sensitivity"]
naive_bayes_test_specificity <- naive_bayes_test_cfm$byClass["Specificity"]
Model_test_Accuracy <- bind_rows(Model_test_Accuracy, tibble(Model = "Naive Bayes (naive_bayes)", Accuracy = naive_bayes_test_accuracy, Sensitivity = naive_bayes_test_sensitivity, Specificity = naive_bayes_test_specificity))
```

```{r}
# Model Validation
naive_bayes_validation <- predict(naive_bayes_train, newdata = validation)
# Model Accuracy On Validation Set using Confusion Matrix
naive_bayes_validation_cfm <- confusionMatrix(naive_bayes_validation, validation$DEATH_EVENT, positive = "Yes")
naive_bayes_validation_accuracy <- naive_bayes_validation_cfm$overall["Accuracy"]
naive_bayes_validation_sensitivity <- naive_bayes_validation_cfm$byClass["Sensitivity"]
naive_bayes_validation_specificity <- naive_bayes_validation_cfm$byClass["Specificity"]
Model_validation_Accuracy <- bind_rows(Model_validation_Accuracy, tibble(Model = "Naive Bayes (naive_bayes)", Accuracy = naive_bayes_validation_accuracy, Sensitivity = naive_bayes_validation_sensitivity, Specificity = naive_bayes_validation_specificity))
# Remove redundant variables
rm(naive_bayes_train, naive_bayes_test,naive_bayes_test_cfm, naive_bayes_test_accuracy, naive_bayes_test_sensitivity, naive_bayes_test_specificity, naive_bayes_validation, naive_bayes_validation_cfm, naive_bayes_validation_accuracy, naive_bayes_validation_sensitivity, naive_bayes_validation_specificity)
```

The calculated model performance metrics on the edx test set are listed below in Table 5.

```{r}
# Model Accuracy on Test Set
Model_test_Accuracy %>% knitr::kable(row.names=FALSE, caption = "Model Accuracy on Test Set", booktabs = T, linesep = "", align = "lccc", digits=5) %>% kable_styling(full_width = FALSE, latex_options = c("hold_position"))
```

The calculated model performance metrics on the validation set are listed below in Table 6.

```{r}
# Model Accuracy on Validation Set
Model_validation_Accuracy %>% knitr::kable(row.names=FALSE, caption = "Model Accuracy on Validation Set", booktabs = T, linesep = "", align = "lccc", digits=5) %>% kable_styling(full_width = FALSE, position = "center", latex_options = c("hold_position"))
```


### Decision Tree (rpart)

A Decision Tree is a tree diagram that is used to make a decision based on the choices called branches. 

The Decision Tree algorithm is a classification method where decision trees are created recursively by splitting the nodes until a majority of records have been classified under specific class labels or a particular stopping criterion is reached[6].

```{r}
# Model Training and Testing
set.seed(1, sample.kind = "Rounding")
# Model Training
rpart_train <- train(DEATH_EVENT~.,data = edx_train_set, method = "rpart")
# Model Testing
rpart_test <- predict(rpart_train, edx_test_set)
# Model Accuracy On Test Set using Confusion Matrix
rpart_test_cfm <- confusionMatrix(rpart_test, edx_test_set$DEATH_EVENT, positive = "Yes")
rpart_test_accuracy <- rpart_test_cfm$overall["Accuracy"]
rpart_test_sensitivity <- rpart_test_cfm$byClass["Sensitivity"]
rpart_test_specificity <- rpart_test_cfm$byClass["Specificity"]
Model_test_Accuracy <- bind_rows(Model_test_Accuracy, tibble(Model = "Decision Tree (rpart)", Accuracy = rpart_test_accuracy, Sensitivity = rpart_test_sensitivity, Specificity = rpart_test_specificity))
```

```{r}
# Model Validation
rpart_validation <- predict(rpart_train, newdata = validation)
# Model Accuracy On Validation Set using Confusion Matrix
rpart_validation_cfm <- confusionMatrix(rpart_validation, validation$DEATH_EVENT, positive = "Yes")
rpart_validation_accuracy <- rpart_validation_cfm$overall["Accuracy"]
rpart_validation_sensitivity <- rpart_validation_cfm$byClass["Sensitivity"]
rpart_validation_specificity <- rpart_validation_cfm$byClass["Specificity"]
Model_validation_Accuracy <- bind_rows(Model_validation_Accuracy, tibble(Model = "Decision Tree (rpart)", Accuracy = rpart_validation_accuracy, Sensitivity = rpart_validation_sensitivity, Specificity = rpart_validation_specificity))
# Remove redundant variables
rm(rpart_train, rpart_test,rpart_test_cfm, rpart_test_accuracy, rpart_test_sensitivity, rpart_test_specificity, rpart_validation, rpart_validation_cfm, rpart_validation_accuracy, rpart_validation_sensitivity, rpart_validation_specificity)
```

The calculated model performance metrics on the edx test set are listed below in Table 7.

```{r}
# Model Accuracy on Test Set
Model_test_Accuracy %>% knitr::kable(row.names=FALSE, caption = "Model Accuracy on Test Set", booktabs = T, linesep = "", align = "lccc", digits=5) %>% kable_styling(full_width = FALSE, latex_options = c("hold_position"))
```

The calculated model performance metrics on the validation set are listed below in Table 8.

```{r}
# Model Accuracy on Validation Set
Model_validation_Accuracy %>% knitr::kable(row.names=FALSE, caption = "Model Accuracy on Validation Set", booktabs = T, linesep = "", align = "lccc", digits=5) %>% kable_styling(full_width = FALSE, position = "center", latex_options = c("hold_position"))
```

### Random Forest (rf)

The Random Forest classifier is an ensemble method that trains several decision trees in parallel on various subsets of the training data set using different subsets of available features[6]. 

The final decision is a result of aggregation of individual tree decisions. The ensemble design of the Random Forest helps avoid over-fitting[6].

```{r}
# Model Training and Testing
set.seed(1, sample.kind = "Rounding")
# Model Training
tuning <- data.frame(mtry = 4)
rf_train <- train(DEATH_EVENT~.,data = edx_train_set, method = "rf", tuneGrid = tuning, importance = TRUE)
# Model Testing
rf_test <- predict(rf_train, edx_test_set)
# Model Accuracy On Test Set using Confusion Matrix
rf_test_cfm <- confusionMatrix(rf_test, edx_test_set$DEATH_EVENT, positive = "Yes")
rf_test_accuracy <- rf_test_cfm$overall["Accuracy"]
rf_test_sensitivity <- rf_test_cfm$byClass["Sensitivity"]
rf_test_specificity <- rf_test_cfm$byClass["Specificity"]
Model_test_Accuracy <- bind_rows(Model_test_Accuracy, tibble(Model = "Random Forest (rf)", Accuracy = rf_test_accuracy, Sensitivity = rf_test_sensitivity, Specificity = rf_test_specificity))
```

```{r}
# Model Validation
rf_validation <- predict(rf_train, newdata = validation)
# Model Accuracy On Validation Set using Confusion Matrix
rf_validation_cfm <- confusionMatrix(rf_validation, validation$DEATH_EVENT, positive = "Yes")
rf_validation_accuracy <- rf_validation_cfm$overall["Accuracy"]
rf_validation_sensitivity <- rf_validation_cfm$byClass["Sensitivity"]
rf_validation_specificity <- rf_validation_cfm$byClass["Specificity"]
Model_validation_Accuracy <- bind_rows(Model_validation_Accuracy, tibble(Model = "Random Forest (rf)", Accuracy = rf_validation_accuracy, Sensitivity = rf_validation_sensitivity, Specificity = rf_validation_specificity))
# Remove redundant variables
rm(rf_train, rf_test,rf_test_cfm, rf_test_accuracy, rf_test_sensitivity, rf_test_specificity, tuning, rf_validation, rf_validation_cfm, rf_validation_accuracy, rf_validation_sensitivity, rf_validation_specificity)
```

The calculated model performance metrics on edx the test set are listed below in Table 9. The tuning parameter mtry = 4 results in the highest accuracy.

```{r}
# Model Accuracy on Test Set
Model_test_Accuracy %>% knitr::kable(row.names=FALSE, caption = "Model Accuracy on Test Set", booktabs = T, linesep = "", align = "lccc", digits=5) %>% kable_styling(full_width = FALSE, latex_options = c("hold_position"))
```

The calculated model performance metrics on the validation set are listed below in Table 10.

```{r}
# Model Accuracy on Validation Set
Model_validation_Accuracy %>% knitr::kable(row.names=FALSE, caption = "Model Accuracy on Validation Set", booktabs = T, linesep = "", align = "lccc", digits=5) %>% kable_styling(full_width = FALSE, position = "center", latex_options = c("hold_position"))
```



### Support Vector Machines with Linear Kernel (svmLinear2)

Support Vector Machine is a Supervised Learning technique that can be used for Classification. 

Support Vector Machines transforms the original feature space into a higher dimensional space based on a user-defined kernel function and then finds support vectors to maximize the separation (margin) between two classes[6]. 

Different Kernels are implemented in the Support Vector Machine to transform the feature space. The Linear Kernel is the most commonly used Kernel where data is assumed to be linearly separable[6].

```{r}
# Model Training and Testing
set.seed(1, sample.kind = "Rounding")
# Model Training
svmLinear2_train <- train(DEATH_EVENT~.,data = edx_train_set, method = "svmLinear2")
# Model Testing
svmLinear2_test <- predict(svmLinear2_train, edx_test_set)
# Model Accuracy On Test Set using Confusion Matrix
svmLinear2_test_cfm <- confusionMatrix(svmLinear2_test, edx_test_set$DEATH_EVENT, positive = "Yes")
svmLinear2_test_accuracy <- svmLinear2_test_cfm$overall["Accuracy"]
svmLinear2_test_sensitivity <- svmLinear2_test_cfm$byClass["Sensitivity"]
svmLinear2_test_specificity <- svmLinear2_test_cfm$byClass["Specificity"]
Model_test_Accuracy <- bind_rows(Model_test_Accuracy, tibble(Model = "Support Vector Machines with Linear Kernel (svmLinear2)", Accuracy = svmLinear2_test_accuracy, Sensitivity = svmLinear2_test_sensitivity, Specificity = svmLinear2_test_specificity))
```

```{r}
# Model Validation
svmLinear2_validation <- predict(svmLinear2_train, newdata = validation)
# Model Accuracy On Validation Set using Confusion Matrix
svmLinear2_validation_cfm <- confusionMatrix(svmLinear2_validation, validation$DEATH_EVENT, positive = "Yes")
svmLinear2_validation_accuracy <- svmLinear2_validation_cfm$overall["Accuracy"]
svmLinear2_validation_sensitivity <- svmLinear2_validation_cfm$byClass["Sensitivity"]
svmLinear2_validation_specificity <- svmLinear2_validation_cfm$byClass["Specificity"]
Model_validation_Accuracy <- bind_rows(Model_validation_Accuracy, tibble(Model = "Support Vector Machines with Linear Kernel (svmLinear2)", Accuracy = svmLinear2_validation_accuracy, Sensitivity = svmLinear2_validation_sensitivity, Specificity = svmLinear2_validation_specificity))
# Remove redundant variables
rm(svmLinear2_train, svmLinear2_test,svmLinear2_test_cfm, svmLinear2_test_accuracy, svmLinear2_test_sensitivity, svmLinear2_test_specificity, svmLinear2_validation, svmLinear2_validation_cfm, svmLinear2_validation_accuracy, svmLinear2_validation_sensitivity, svmLinear2_validation_specificity)
```

The calculated model performance metrics on the edx test set are listed below in Table 11.

```{r}
# Model Accuracy on Test Set
Model_test_Accuracy %>% knitr::kable(row.names=FALSE, caption = "Model Accuracy on Test Set", booktabs = T, linesep = "", align = "lccc", digits=5) %>% kable_styling(full_width = FALSE, latex_options = c("hold_position"))
```

The calculated model performance metrics on the validation set are listed below in Table 12.

```{r}
# Model Accuracy on Validation Set
Model_validation_Accuracy %>% knitr::kable(row.names=FALSE, caption = "Model Accuracy on Validation Set", booktabs = T, linesep = "", align = "lccc", digits=5) %>% kable_styling(full_width = FALSE, position = "center", latex_options = c("hold_position"))
```

All 5 Models have resulted in good Accuracy, Sensitivity and Specificity. Random Forest is the best performing model among all resulting in a prediction accuracy of 0.96774.


# **Conclusion**

Hearth Failure Prediction Clinical Data Set is used to develop the Heart Failure Prediction Model. The data is pre-processed and split into train (edx) and validation sets to develop and validate the model respectively. Data exploration and analysis is performed to understand the data thoroughly and to estimate the importance of different features.

Classification Models - Logistic Regression, Naive Bayes, Decision Tree, Random Forest and Support Vector Machines are considered to develop Heart Prediction Model using edx train set and evaluated using edx test set. The Model performance is evaluated based on Accuracy, Sensitivity and Specificity metrics using a confusion matrix. The Model Accuracy ranges between 0.79-0.89 for the test set and 0.81-0.97 for the validation set. Random Forest results in the best prediction model having an accuracy of 0.96774. The Model metrics Accuracy, Sensitivity and Specificity are in a reasonably good range.

The models can help identify at-risk individuals at an early stage and prevent causalities. Also, it can help hospitals prioritize critical patients.

## Limitation

The used data set is smaller in size but the execution process could become very time-consuming while dealing with large data sets due to limited machine memory. Also, the algorithm has to run again every time if a new patient is included which is complex to perform on a large data set.   
The developed models using smaller data sets could not be as reliable as the ones developed using larger data sets. Also, additional related details about the patient like weight and occupation could be useful. 

## Future Scope

A larger data set could be explored to build more reliable models.

The Heart Failure Prediction Model is created using the most popular classification models. A more advanced or alternate modeling approach like Boosting Models, Multi-layer Models, Neural Networks etc. can be explored for better prediction. 


\newpage
# **References**

1. [World Health Organization, Fact Sheet, Cardiovascular Diseases](https://www.who.int/news-room/fact-sheets/detail/cardiovascular-diseases-(cvds))
2. [Heart Failure Clinical Records Data Set, UCI Machine Learning Repository, Center for Machine Learning and Intelligent Systems ](https://archive.ics.uci.edu/ml/datasets/Heart+failure+clinical+records)
3. [Pablo Casas, January 2019, Data Science Live Book](https://livebook.datascienceheroes.com/)
4. [Irizarry, Rafael A. 2020. Introduction to Data Science: Data Analysis and Prediction Algorithms with r. CRC Press](https://rafalab.github.io/dsbook/)
5. [David Dalpiaz, October 2020, R for Statistical Learning](https://daviddalpiaz.github.io/r4sl/)
6. [Park and Hyeoun-Ae, April 2013, An Introduction to Logistic Regression: From Basic Concepts to Interpretation with Particular Attention to Nursing Domain](https://synapse.koreamed.org/upload/synapsedata/pdfdata/0006jkan/jkan-43-154.pdf)
7. [Siddharth Misra and Hao Li, October 2019, Machine Learning for Subsurface Characterization](https://www.sciencedirect.com/book/9780128177365/machine-learning-for-subsurface-characterization)